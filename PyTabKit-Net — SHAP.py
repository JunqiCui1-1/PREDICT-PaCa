# -*- coding: utf-8 -*-
"""Untitled77.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tmvaBxkpCK70PzUHQ0h53_KL7V9CXe51
"""

# =============================================================================
# Component 1 — PyTabKit-Net — SHAP (Continuous-only, Top-10, Fast Minimal Version)
#
# GITHUB-STYLE HEADER
# -----------------------------------------------------------------------------
# DESCRIPTION
#   Model-agnostic SHAP with KernelExplainer for PyTabKit-Net (or sklearn fallback).
#   Computes SHAP values on continuous features only, selects Top-10 by mean |SHAP|,
#   and renders a bar chart + beeswarm to ./outputs/.
#
# ASSUMPTIONS (imported from the training context)
#   - NUM_COLS: list[str]      # numeric feature columns used by the model
#   - Xtr_df:  pd.DataFrame    # training features (pre-column-mapping)
#   - Xva_df:  pd.DataFrame    # validation features (pre-column-mapping)
#   - Xva_df_distill (optional): if present, includes 'teacher_logit'
#   - prep_for_ptk: callable   # converts df to PyTabKit input (if PTK is used)
#   - PTK: fitted PyTabKit model with predict_proba(...) or None
#   - clf: fitted sklearn MLP fallback with predict_proba(...)
#   - OUTDIR: str              # output directory, e.g., "./outputs"
#   - SEED: int
#
# OUTPUTS (relative to repo root)
#   - ./outputs/shap_bar_top10.png
#   - ./outputs/shap_beeswarm_top10.png
#
# NOTES
#   - No auto-install here; add `shap` to requirements.txt.
#   - Tunable speed dials: BGN (background size), K_BG (kmeans clusters),
#     NEVAL (evaluation subset size), NSAMPLES (KernelExplainer samples).
# =============================================================================

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# --- import shap (no auto-install; fail with a clear message) ---
try:
    import shap
except ImportError as e:
    raise ImportError(
        "shap is required for this section. Please add `shap` to requirements.txt "
        "and `pip install -r requirements.txt` before running."
    ) from e

np.random.seed(SEED)

# -----------------------------------------------------------------------------
# 1) Continuous-only feature set (exclude engineered columns like 'teacher_logit')
# -----------------------------------------------------------------------------
CONT_COLS = list(NUM_COLS)
for _c in ("teacher_logit",):
    if _c in CONT_COLS:
        CONT_COLS.remove(_c)

# -----------------------------------------------------------------------------
# 2) Expand numeric-only matrix back to a full input frame
#    - We sample a categorical template (with replacement) from validation,
#      then overwrite continuous columns with the numeric matrix
# -----------------------------------------------------------------------------
def _make_full_df_from_numeric(X_num_np: np.ndarray) -> pd.DataFrame:
    """
    Parameters
    ----------
    X_num_np : np.ndarray
        Shape (m, len(CONT_COLS)) numeric matrix.

    Returns
    -------
    pd.DataFrame
        Full input DataFrame matching the model's expected schema. Categorical
        columns are copied from a sampled validation template; numeric columns
        are replaced by X_num_np.
    """
    m = X_num_np.shape[0]
    base_df = Xva_df_distill.copy() if "Xva_df_distill" in globals() else Xva_df.copy()
    # Sample with replacement so m can exceed the validation size
    base_slice = base_df.sample(n=m, replace=True, random_state=SEED).reset_index(drop=True).copy()
    # Vectorized overwrite of continuous columns
    base_slice.loc[:, CONT_COLS] = X_num_np.astype(float)
    return base_slice

# -----------------------------------------------------------------------------
# 3) Model prediction function (numeric-only → full df → P(y=1))
# -----------------------------------------------------------------------------
def f_num(X):
    """
    KernelExplainer callback: accept numeric-only matrix, expand to full df,
    then return predicted probability P(y=1).
    """
    X = np.asarray(X, dtype=float)
    df_full = _make_full_df_from_numeric(X)
    # Prefer PyTabKit if available; otherwise use sklearn fallback
    if "PTK" in globals() and PTK is not None and callable(getattr(PTK, "predict_proba", None)):
        df_in = prep_for_ptk(df_full)
        return PTK.predict_proba(df_in)[:, 1]
    else:
        return clf.predict_proba(df_full)[:, 1]

# -----------------------------------------------------------------------------
# 4) Background / evaluation sets (continuous-only) + k-means compression
#    Speed strategy:
#      - background: sample 600 → kmeans to 30
#      - evaluation: sample 300
#      - nsamples:   150 (typical range 150–300)
# -----------------------------------------------------------------------------
BGN   = min(600, len(Xtr_df))
NEVAL = min(300, len(Xva_df))

background_num = Xtr_df[CONT_COLS].sample(BGN, random_state=SEED)
eval_num       = Xva_df[CONT_COLS].sample(NEVAL, random_state=SEED)

K_BG = 30
background_k = shap.kmeans(background_num.to_numpy(), K_BG)

# -----------------------------------------------------------------------------
# 5) KernelExplainer (model-agnostic; link='logit' for probability outputs)
# -----------------------------------------------------------------------------
explainer = shap.KernelExplainer(f_num, background_k, link="logit")
NSAMPLES  = 150
shap_values = explainer.shap_values(eval_num.to_numpy(), nsamples=NSAMPLES)
# shap_values: (NEVAL, n_features) array for binary output

# -----------------------------------------------------------------------------
# 6) Select Top-10 by mean |SHAP|
# -----------------------------------------------------------------------------
mean_abs    = np.abs(shap_values).mean(axis=0)
top_idx     = np.argsort(mean_abs)[-10:][::-1]
top_features = [CONT_COLS[i] for i in top_idx]
sv_top      = shap_values[:, top_idx]
eval_top    = eval_num.iloc[:, top_idx]

# -----------------------------------------------------------------------------
# 7) Figure 1 — Top-10 Bar (light blue)
# -----------------------------------------------------------------------------
plt.figure(figsize=(7.8, 6.8), dpi=400)
bar_vals  = mean_abs[top_idx][::-1]  # plot from small→large for horizontal bars
bar_names = list(reversed(top_features))
plt.barh(range(len(bar_names)), bar_vals, color="#8EC5FF")
plt.yticks(range(len(bar_names)), bar_names, fontsize=10)
plt.xlabel("Mean |SHAP value|", fontsize=11)
plt.title("PyTabKit-Net — Top-10 features (bar)", fontsize=13)
plt.tight_layout()
plt.savefig(os.path.join(OUTDIR, "shap_bar_top10.png"))
plt.close()

# -----------------------------------------------------------------------------
# 8) Figure 2 — Top-10 Beeswarm
# -----------------------------------------------------------------------------
plt.figure(figsize=(7.8, 6.8), dpi=400)
# Note: shap.summary_plot handles the color mapping; keep show=False for script mode.
shap.summary_plot(sv_top, eval_top, feature_names=top_features, plot_type="dot", show=False)
plt.title("PyTabKit-Net — Top-10 features (beeswarm)")
plt.tight_layout()
plt.savefig(os.path.join(OUTDIR, "shap_beeswarm_top10.png"))
plt.close()

print(f"[ok] SHAP figures saved (K_BG={K_BG}, NEVAL={NEVAL}, nsamples={NSAMPLES}):")
print(" -", os.path.join(OUTDIR, "shap_bar_top10.png"))
print(" -", os.path.join(OUTDIR, "shap_beeswarm_top10.png"))